import csv
import sys
import pandas as pd
import re
import numpy as np
from joblib import Memory

memory = Memory("/tmp/", verbose=3)

nst_path = "resources/nst/swe030224NST.pron"

COLUMNS = [
    "orthography",
    "parts_of_speech",
    "morphology",
    "decomposition",
    "decomposition_pos",
    "source",
    "lang",
    "is_garbage",
    "domain",
    "is_acronym",
    "acronym_expansion",
    "trans_1",
    "trans_2",
    "trans_3",
    "trans_4",
    "trans_5",
    "trans_6",
    "trans_7",
    "trans_8",
    "trans_9",
    "trans_10",
    "trans_11",
    "trans_12",
    "trans_13",
    "trans_14",
    "trans_15",
    "trans_16",
    "trans_autogenerated",
    "set_id",
    "set_name",
    "stylistic_information",
    "inflector_role",
    "lemma",
    "inflection_rule",
    "morph_label",
    "compounder_code",
    "semantic_info",
    "disp_1",
    "disp_2",
    "disp_3",
    "disp_4",
    "disp_5",
    "disp_6",
    "disp_7",
    "disp_8",
    "disp_9",
    "frequency",
    "original_orthography",
    "comment_field",
    "update_info",
    "unique_id",
]


class _nst_dialect(csv.Dialect):
    """Describe the usual properties of Excel-generated CSV files."""

    delimiter = ";"
    doublequote = True
    skipinitialspace = False
    lineterminator = "\r\n"
    quoting = csv.QUOTE_NONE


def to_nst_format(transcriptions):
    nst_format = {}
    for orthography, transcription in transcriptions.items():
        arr = [float("NaN")] * 51
        arr[0] = orthography
        arr[3] = orthography
        arr[11] = transcription
        nst_format[orthography] = arr
    return nst_format


@memory.cache
def load_lexicon(path):
    """
    Returns NST lexicon as pandas.DataFrame.
    """
    print("Reading NST lexicon from {}".format(path))
    function_words = [
        "i",
        "att",
        "den",
        "det",
        "så",
        "och",
        "men",
        "för",
        "som",
        "då",
        "när",
        "min",
        "din",
        "vår",
        "han",
        "hon",
        "hans",
        "dess",
        "nog",
        "med",
        "kan",
        "hur",
        "var",
        "vem",
        "en",
        "ett",
        "av",
        "till",
        "från",
        "bland",
        "längs",
        "å",
        "dels",
        "då",
        "fram",
        "bak",
    ]
    missing = pd.DataFrame.from_dict(
        to_nst_format(
            {
                "på": '"po:',
                "efter": '"Ef$ter',
                "av": '"A:v',
                "som": '"sOm',
                "den": '"dE:n',
                "det": '"de:t',
                "2018": '"tvo: "t}:$sen ""A:$t`On',
                "trump": '"tru0mp',
                "2019": '"tvo: "t}:$sen ""nI$tOn',
                "shl": '"Es "ho: "El',
                "flera": '""fle:$ra',
                "2017": '"tvo:%t}:$sen%x\\u0$tOn',
                "10": '""ti:$U',
                "få": '"fo:',

                "5": '"fEm',
                "1": '"Et',
                "zlatan": '""fla:$tan',
                "bra": '"brA:',
                "7": '"x}:',
                "utanför": '""}:$tan$%f2:r',
                "sd": '"Es "dE',
                "än": '"E:n',
                "sveriges": '"svEr$jes',
                "trumps": "tru0mps",
                "bort": '"bOt`',
                "mer": '"mEr',
                "löfven": 'l2:$"ve:n',
                "stort": '"stu:t`',
                "bakom": '""bA:%kOm',
                "2": '"tvo:',
                "6": '"sEks',
                "hittad": '""hI$tad',
                "kim": '"kIm',
                "15": '""fEm$tOn',
                "9": '""ni:$U',
                "8": '""O$ta',
                "20": '""s\'}:$gU',
                "3": '"tre:',
                "12": '"tOlv',
                "topptipset": '"tOp "tIp$set',
                "mest": '"mEst',
                "11": '""El$va',
                "v64": '"ve: sek$stI$U$""fy:$ra',
                "30": '""trE$tI',
                "4": '""fy:$ra',
                "många": '""mON$a',
                "000": '"nOl "nOl "nOl',
                "v86": '"ve: O$tI$U$"sEks',
                "gw": '"ge:$ve',
                "volvo": '"bOl$bu:',
                "andreas": 'and$""re:$as',
                "andreaa": 'and$""re:$a',
                "martin": '"ma$t`In',
                "18": '""A:$t`On',
                "ibrahimovic": '""i:$bra$hIm$nO$vIts\'',
                "13": '""trE$tOn',
                "16": '""sEk$stOn',
                "17": '""x\\u0$tOn',
                "14": '""fju:$t`On',
                "avstängd": '""A:v$%stENd',
                "malin": '"mA:$lIn',
                "bachner": '"ba$kner',
                "rånad": '""ro:$nad',
                "lånad": '""lo:$nad',
                "brynäs": '"by:$nE:s',
                "25": "s'}:$gU$\"fEm",
                "100": '"hu0n$dra',
                "19": '""nI$tOn',
                "hemnet": '"hEmn$et',
                "förd": '"f2:d`',
                "johaug": '""ju:$%hA:g',
                "misshandlad": '""mI$s%hand$lad',
                "40": '"f9$t`I$U',
                "21": "s'}:$gU$\"Et",
                "22": "s'}:$gU$\"tvo:",
                "häktad": '""hEk$tad',
                "jäktad": '""jEk$tad',
                "enligt": '""e:$nlIkt',
                "facebook": '"fEjs$bu:k',
                "facebooks": '"fEjs$bu:ks',
                "zlatans": '""fla:$tan',
                "där": '"dE:r',
                "dance": '"dE:ns',
                "meghan": '""mE$gan',
                "27": "s'}:$gU$\"x\\}:",
                "ronaldo": 'ro$"nal$dU',
                "redhawk": '"rEd$hA:k',
                "redhawks": '"rEd$hA:ks',
                "mourinho": 'mU$"ri:$nU',
                "detta": '""dE$ta',
                "23": "s'}:$gU$\"tre:",
                "dömd": '"d9md',
                "24": "s'}:$gU$\"fy:$ra",
                "open": '"u:$pen',
                "melania": 'me$"lA:$nI$a',
                "26": "s'}:$gU$\"sEks",
                "let": "lEt",
                "lets": "lEts",
                "71": 'x\\u0$tI$U$"Et',
                "instagram": 'In$sta$"gram',
                "wilbacher": '"vIl$ba$ker',
                "50": '"fEm$tI$U',
                "minst": '"mInst',
                "northug": '"nu:r%t}:g',
                "neymar": '"nEj$mar',
                "cristiano": '"krI$stI$A:$nU',
                "jong": '"jON',
                "28": 's\'}:$gU$""O$ta',
                "talar": '""tA:$lar',
                "drabbad": '""dra$bad',
                "extra": '"Ek$stra',
                "postnord": '"pOst%nu:d',
                "29": 's\'}:$gU$""ni:$U',
                "ingrosso": 'iN$"grO$sU',
                "psg": '"pe:%Es%e:',
                "akilov": 'a"kI$"lo:v',
                "juventus": 'j}:$""vEn$tu0s',
                "varje": '"var$je',
                "netflix": '"nEt$flIks',
                "tesla": '"tE$sla',
                "0": '"nOl',
                "otäcka": '""u:$%tE$ka',
                "storbråk": '"stu:r%bro:k',
                "31": 'tre$tI$U$"Et',
                "batra": '"bA:$tra',
                "60": '"sEk$stI$U',
                "ifrån": '"I$fro:n',
                "kate": '"kA:$te',
                "mördad": '""m2:$d`ad',
                "metoo": '"mi:%tu:',
                "lindgren": '"lInd%gre:n',
                "när": '"nE:r',
                "sek": '"sEk'
            }
        ),
        orient="index",
        columns=COLUMNS,
    )
    df = pd.read_csv(
        path,
        encoding="utf-8",
        header=None,
        dialect=_nst_dialect,
        dtype={10: np.str_, 9: np.str_},
    )
    df.columns = COLUMNS
    df["orthography"] = df["orthography"].str.lower()
    for fw in function_words:
        fw_trans1 = df.loc[df.orthography == fw, "trans_1"]
        df.loc[df.orthography == fw, "trans_1"] = "?{}".format(fw_trans1)
    return (
        df.append(missing, sort=True)
        .drop_duplicates(subset="orthography", keep="last")
        .set_index("orthography")
        .sort_index()
    )
